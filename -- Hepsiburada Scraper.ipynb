{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5904ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848a62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Sample HepsiBurada Scraper\n",
    "\n",
    "base_url = r\"https://www.hepsiburada.com/\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) Gecko/20100101 Firefox/102.0'\n",
    "}\n",
    "\n",
    "new_product_links = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    url = fr\"https://www.hepsiburada.com/3d-yazici-c-60008975?sayfa={i}\"\n",
    "\n",
    "    r = requests.get(url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    product_list = soup.find_all('li', class_='productListContent-item')\n",
    "    for item in product_list:\n",
    "        for link in item.find_all('a', href=True):\n",
    "            new_product_links.append(base_url + link['href'])\n",
    "print(new_product_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1040d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_product_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e52e6f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.hepsiburada.com//creality-3d-cr-6-se-3d-yazici-p-HBV000015S94D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m r_test \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(test_url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m      3\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r_test\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct-name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "test_url = r\"https://www.hepsiburada.com//creality-3d-cr-6-se-3d-yazici-p-HBV000015S94D\"\n",
    "r_test = requests.get(test_url, headers=headers)\n",
    "soup = BeautifulSoup(r_test.content, 'lxml')\n",
    "\n",
    "\n",
    "name = soup.find('h1', class_='product-name').text.strip()\n",
    "price_before_decimal = soup.find('span', {\"data-bind\": \"markupText:'currentPriceBeforePoint'\"}).text.strip()\n",
    "price_after_decimal = soup.find('span', {\"data-bind\": \"markupText:'currentPriceAfterPoint'\"}).text.strip()\n",
    "price = price_before_decimal + \",\" + price_after_decimal\n",
    "currency = soup.find('span', itemprop='priceCurrency').text.strip()\n",
    "rating = soup.find('span', class_='rating-star').text.strip()\n",
    "num_reviews = soup.find('div', id='comments-container').text.strip().split()[0]\n",
    "printer_3d = {\n",
    "    'name': name,\n",
    "    'price': price,\n",
    "    'rating': rating,\n",
    "    'num_reviews': num_reviews\n",
    "}\n",
    "pprint(printer_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "printer_list = []\n",
    "for link in new_product_links:\n",
    "    r = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    name = soup.find('h1', class_='product-name').text.strip()\n",
    "    price_before_decimal = soup.find('span', {\"data-bind\": \"markupText:'currentPriceBeforePoint'\"}).text.strip()\n",
    "    price_after_decimal = soup.find('span', {\"data-bind\": \"markupText:'currentPriceAfterPoint'\"}).text.strip()\n",
    "    price = price_before_decimal + \",\" + price_after_decimal\n",
    "    currency = soup.find('span', itemprop='priceCurrency').text.strip()\n",
    "    try:\n",
    "        rating = soup.find('span', class_='rating-star').text.strip()\n",
    "    except:\n",
    "        rating = 'no-rating'\n",
    "    try:\n",
    "        num_reviews = soup.find('div', id='comments-container').text.strip().split()[0]\n",
    "    except:\n",
    "        num_reviews = 'no-reviews'\n",
    "    printer_3d = {\n",
    "        'name': name,\n",
    "        'price': price,\n",
    "        'rating': rating,\n",
    "        'num_reviews': num_reviews\n",
    "    }\n",
    "    printer_list.append(printer_3d)\n",
    "    print(f\"Saved: {printer_3d}['name']\")\n",
    "pprint(printer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c52f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Method for scraping sites with dynamic content\n",
    "df = pd.DataFrame()\n",
    "df = pd.DataFrame(printer_list)\n",
    "print(df)\n",
    "df.to_csv('hepsiburada_sample_3d_printer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
